{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torchnet'\n",
    "require 'image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local dir = io.popen(\"ls ../data/sample/\")\n",
    "\n",
    "lines = {}\n",
    "for line in dir:lines() do\n",
    "    lines[#lines + 1] = line\n",
    "end\n",
    "\n",
    "eye_sample_data = {}\n",
    "for i=1, #lines do\n",
    "    track, eye, file_extension = lines[i]:match(\"([^_]+)_([^.]+).([^,]+)\")\n",
    "    index = tonumber(track)\n",
    "    if eye == \"left\" then\n",
    "        eyetype = 1\n",
    "    else\n",
    "        eyetype = 2\n",
    "    end\n",
    "    if eye_sample_data[index] == nil then\n",
    "        eye_sample_data[index] = {}\n",
    "    end\n",
    "    eye_sample_data[index][eyetype] = 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = io.open('../data/sample_crop_data.txt', \"rb\")\n",
    "\n",
    "lines = {}\n",
    "for line in file:lines() do\n",
    "    lines[#lines + 1] = line\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eye_crop_data = {}\n",
    "for i=1, #lines do\n",
    "    track, eye, extension, y0, x0, y1, x1 = lines[i]:match(\"([^,]+)_([^.]+).([^,]+),([^,]+),([^,]+),([^,]+),([^,]+)\")\n",
    "    index = tonumber(track)\n",
    "    y0, x0, y1, x1 = tonumber(y0), tonumber(x0), tonumber(y1), tonumber(x1)\n",
    "    if eye == 'left' then\n",
    "        eyetype = 1\n",
    "    else\n",
    "        eyetype = 2\n",
    "    end\n",
    "    if eye_crop_data[index] == nil then\n",
    "        eye_crop_data[index] = {}\n",
    "    end\n",
    "    eye_crop_data[index][eyetype] = {x0, y0, x1, y1}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = 0\n",
    "for k, v in pairs(eye_sample_data) do\n",
    "    length = length+1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Index 1 --File track\n",
    "-- Index 2 --Left or Right Eye\n",
    "-- Index 3 --Pairing Eye Index\n",
    "-- Index 4 --Cropping X0\n",
    "-- Index 5 --Cropping Y0\n",
    "-- Index 6 --Cropping X1\n",
    "-- Index 7 --Cropping Y1\n",
    "\n",
    "eye_sample_tensor = torch.LongTensor(length*2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "for k, v in pairs(eye_sample_data) do\n",
    "    -- Left eye\n",
    "    eye_sample_tensor[index][1] = k\n",
    "    eye_sample_tensor[index][2] = 1\n",
    "    eye_sample_tensor[index][3] = index+1\n",
    "    \n",
    "    --Dont'have the cropping information yet\n",
    "    eye_sample_tensor[index][4] = eye_crop_data[k][1][1]\n",
    "    eye_sample_tensor[index][5] = eye_crop_data[k][1][2]\n",
    "    eye_sample_tensor[index][6] = eye_crop_data[k][1][3]\n",
    "    eye_sample_tensor[index][7] = eye_crop_data[k][1][4]\n",
    "    index = index + 1\n",
    "    \n",
    "    -- Right eye\n",
    "    eye_sample_tensor[index][1] = k\n",
    "    eye_sample_tensor[index][2] = 2\n",
    "    eye_sample_tensor[index][3] = index - 1\n",
    "    \n",
    "    --Don't have the cropping information yet\n",
    "    eye_sample_tensor[index][4] = eye_crop_data[k][2][1]\n",
    "    eye_sample_tensor[index][5] = eye_crop_data[k][2][2]\n",
    "    eye_sample_tensor[index][6] = eye_crop_data[k][2][3]\n",
    "    eye_sample_tensor[index][7] = eye_crop_data[k][2][4]\n",
    "    index = index + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   13     1     2   282     0  2310  1944\n",
       "   13     2     1   282     0  2310  1944\n",
       "   17     1     4   705   101  3174  2563\n",
       "   17     2     3   705   101  3174  2563\n",
       "   16     1     6   318     0  3600  2592\n",
       "   16     2     5   324     0  3576  2592\n",
       "   10     1     8   855   135  3865  3132\n",
       "   10     2     7   858   137  3865  3131\n",
       "   15     1    10   860    45  4049  3234\n",
       "   15     2     9   860    46  4050  3234\n",
       "[torch.LongTensor of size 10x7]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye_sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save('../data/sample_full_metadata.t7', eye_sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
